{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Impact on Food Delivery - Predictive Modeling\n",
    "\n",
    "This notebook focuses on:\n",
    "1. Feature engineering\n",
    "2. Model development for predicting delivery metrics\n",
    "3. Model evaluation and comparison\n",
    "4. Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the processed data\n",
    "df = pd.read_csv('../data/processed_data.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create features for modeling\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Temporal features\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Weather interaction features\n",
    "    df['temp_wind_interaction'] = df['temperature'] * df['wind_speed']\n",
    "    df['feels_like_diff'] = df['feels_like'] - df['temperature']\n",
    "    \n",
    "    # Weather severity features\n",
    "    weather_severity = {\n",
    "        'Clear': 0,\n",
    "        'Clouds': 1,\n",
    "        'Mist': 2,\n",
    "        'Drizzle': 3,\n",
    "        'Rain': 4,\n",
    "        'Snow': 5,\n",
    "        'Thunderstorm': 6\n",
    "    }\n",
    "    df['weather_severity'] = df['weather_condition'].map(weather_severity)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create features\n",
    "df_features = create_features(df)\n",
    "\n",
    "# Define features for modeling\n",
    "numeric_features = ['temperature', 'feels_like', 'humidity', 'wind_speed',\n",
    "                   'temp_wind_interaction', 'feels_like_diff', 'weather_severity']\n",
    "categorical_features = ['city', 'weather_condition', 'is_weekend']\n",
    "temporal_features = ['hour', 'day_of_week', 'month']\n",
    "\n",
    "# Define target variables\n",
    "targets = ['num_orders', 'avg_delivery_time', 'cancellation_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_pipeline(model):\n",
    "    \"\"\"Create a preprocessing and modeling pipeline\"\"\"\n",
    "    numeric_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(drop='first', sparse=False)\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(random_state=42, verbose=False)\n",
    "}\n",
    "\n",
    "# Train and evaluate models for each target\n",
    "results = {}\n",
    "for target in targets:\n",
    "    print(f\"\\nModeling for {target}:\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df_features[numeric_features + categorical_features + temporal_features]\n",
    "    y = df_features[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    target_results = {}\n",
    "    for name, model in models.items():\n",
    "        # Create and train pipeline\n",
    "        pipeline = create_pipeline(model)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        target_results[name] = {\n",
    "            'mse': mse,\n",
    "            'rmse': np.sqrt(mse),\n",
    "            'r2': r2\n",
    "        }\n",
    "        \n",
    "        print(f\"{name} - RMSE: {np.sqrt(mse):.4f}, R2: {r2:.4f}\")\n",
    "    \n",
    "    results[target] = target_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# SHAP analysis for XGBoost model\n",
    "for target in targets:\n",
    "    print(f\"\\nFeature Importance Analysis for {target}:\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df_features[numeric_features + categorical_features + temporal_features]\n",
    "    y = df_features[target]\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    model = xgb.XGBRegressor(random_state=42)\n",
    "    pipeline = create_pipeline(model)\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    explainer = shap.TreeExplainer(pipeline.named_steps['regressor'])\n",
    "    shap_values = explainer.shap_values(pipeline.named_steps['preprocessor'].transform(X))\n",
    "    \n",
    "    # Plot SHAP summary\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, pipeline.named_steps['preprocessor'].transform(X),\n",
    "                      feature_names=pipeline.named_steps['preprocessor'].get_feature_names_out(),\n",
    "                      show=False)\n",
    "    plt.title(f'Feature Importance for {target}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictions and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def predict_delivery_metrics(weather_data, city):\n",
    "    \"\"\"Predict delivery metrics for given weather conditions\"\"\"\n",
    "    # Prepare input data\n",
    "    input_data = pd.DataFrame({\n",
    "        'temperature': [weather_data['temperature']],\n",
    "        'feels_like': [weather_data['feels_like']],\n",
    "        'humidity': [weather_data['humidity']],\n",
    "        'wind_speed': [weather_data['wind_speed']],\n",
    "        'weather_condition': [weather_data['weather_condition']],\n",
    "        'city': [city],\n",
    "        'date': [pd.Timestamp.now()]\n",
    "    })\n",
    "    \n",
    "    # Create features\n",
    "    input_features = create_features(input_data)\n",
    "    \n",
    "    # Make predictions for each target\n",
    "    predictions = {}\n",
    "    for target in targets:\n",
    "        model = models['XGBoost']\n",
    "        pipeline = create_pipeline(model)\n",
    "        pipeline.fit(X, df_features[target])\n",
    "        \n",
    "        pred = pipeline.predict(input_features[numeric_features + categorical_features + temporal_features])\n",
    "        predictions[target] = pred[0]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example prediction\n",
    "sample_weather = {\n",
    "    'temperature': 20,\n",
    "    'feels_like': 22,\n",
    "    'humidity': 65,\n",
    "    'wind_speed': 5,\n",
    "    'weather_condition': 'Clear'\n",
    "}\n",
    "\n",
    "predictions = predict_delivery_metrics(sample_weather, 'New York')\n",
    "print(\"\\nPredicted Delivery Metrics:\")\n",
    "for metric, value in predictions.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Findings and Recommendations\n",
    "\n",
    "1. Model Performance:\n",
    "   - Compare the performance of different models\n",
    "   - Identify the best model for each prediction task\n",
    "\n",
    "2. Feature Importance:\n",
    "   - Analyze which weather factors have the strongest impact\n",
    "   - Identify city-specific patterns\n",
    "\n",
    "3. Operational Insights:\n",
    "   - Provide recommendations for delivery operations\n",
    "   - Suggest weather-based staffing adjustments\n",
    "\n",
    "4. Future Improvements:\n",
    "   - Additional features to consider\n",
    "   - Model optimization opportunities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
