{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Impact on Food Delivery - Free API Data Collection\n",
    "\n",
    "This notebook uses completely free APIs and public datasets:\n",
    "1. Open-Meteo API for weather data (no API key required)\n",
    "2. Yelp Academic Dataset for restaurant data\n",
    "3. Public food delivery datasets from Kaggle\n",
    "4. Synthetic data generation for missing components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Weather Data Collection using Open-Meteo API\n",
    "\n",
    "Open-Meteo is a free weather API that doesn't require an API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting data for New York\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:02<00:11,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting data for Los Angeles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:05<00:07,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting data for Chicago\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:07<00:04,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting data for Houston\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:10<00:02,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting data for Phoenix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving weather data...\n",
      "Weather data saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_weather_data(latitude, longitude, start_date, end_date):\n",
    "    \"\"\"Collect weather data from National Weather Service API\"\"\"\n",
    "    # First, get the grid endpoint for the location\n",
    "    point_url = f\"https://api.weather.gov/points/{latitude},{longitude}\"\n",
    "    \n",
    "    try:\n",
    "        # Get grid endpoint\n",
    "        response = requests.get(point_url, headers={'User-Agent': 'WeatherStudyProject'})\n",
    "        response.raise_for_status()\n",
    "        grid_data = response.json()\n",
    "        \n",
    "        # Get the forecast grid endpoint\n",
    "        forecast_url = grid_data['properties']['forecastGridData']\n",
    "        \n",
    "        # Get weather data\n",
    "        response = requests.get(forecast_url, headers={'User-Agent': 'WeatherStudyProject'})\n",
    "        response.raise_for_status()\n",
    "        weather_data = response.json()\n",
    "        \n",
    "        # Extract relevant weather properties\n",
    "        properties = weather_data['properties']\n",
    "        \n",
    "        # Create a DataFrame with hourly data\n",
    "        data = {\n",
    "            'temperature': properties['temperature']['values'],\n",
    "            'precipitation': properties['probabilityOfPrecipitation']['values'],\n",
    "            'humidity': properties['relativeHumidity']['values'],\n",
    "            'windSpeed': properties['windSpeed']['values']\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        # Process each weather parameter\n",
    "        for param, values in data.items():\n",
    "            temp_df = pd.DataFrame(values)\n",
    "            temp_df['parameter'] = param\n",
    "            temp_df['validTime'] = pd.to_datetime(temp_df['validTime'].str.split('/').str[0])\n",
    "            temp_df = temp_df.pivot(index='validTime', columns='parameter', values='value')\n",
    "            \n",
    "            if df.empty:\n",
    "                df = temp_df\n",
    "            else:\n",
    "                df = df.join(temp_df)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data for coordinates {latitude},{longitude}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define major US cities with their coordinates\n",
    "cities = {\n",
    "    'New York': {'lat': 40.7128, 'lon': -74.0060},\n",
    "    'Los Angeles': {'lat': 34.0522, 'lon': -118.2437},\n",
    "    'Chicago': {'lat': 41.8781, 'lon': -87.6298},\n",
    "    'Houston': {'lat': 29.7604, 'lon': -95.3698},\n",
    "    'Phoenix': {'lat': 33.4484, 'lon': -112.0740}\n",
    "}\n",
    "\n",
    "# Collect weather data for each city\n",
    "weather_data = []\n",
    "for city, coords in tqdm(cities.items()):\n",
    "    print(f\"\\nCollecting data for {city}\")\n",
    "    df = get_weather_data(coords['lat'], coords['lon'], None, None)\n",
    "    \n",
    "    if df is not None:\n",
    "        df['city'] = city\n",
    "        weather_data.append(df)\n",
    "    \n",
    "    time.sleep(2)  \n",
    "\n",
    "if weather_data:\n",
    "    weather_df = pd.concat(weather_data, ignore_index=True)\n",
    "    print(\"\\nSaving weather data...\")\n",
    "    weather_df.to_csv('../data/weather_data.csv', index=False)\n",
    "    print(\"Weather data saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and examining structure...\n",
      "\n",
      "Weather Data Columns:\n",
      "['temperature', 'precipitation', 'humidity', 'windSpeed', 'city']\n",
      "\n",
      "First few rows of weather data:\n",
      "   temperature  precipitation  humidity  windSpeed      city\n",
      "0     1.666667            0.0      56.0     22.224  New York\n",
      "1     2.222222            NaN      59.0     24.076  New York\n",
      "2     2.777778            NaN      61.0     25.928  New York\n",
      "3     3.333333            NaN      57.0        NaN  New York\n",
      "4     3.888889            NaN      54.0        NaN  New York\n",
      "\n",
      "Restaurant Data Columns:\n",
      "['restaurant_id', 'name', 'city', 'cuisine', 'latitude', 'longitude', 'takeaway', 'delivery', 'opening_hours']\n",
      "\n",
      "First few rows of restaurant data:\n",
      "   restaurant_id               name      city  \\\n",
      "0      296568074     The Brass Rail  New York   \n",
      "1      305499273       Court Street  New York   \n",
      "2      357620442          Sam Sunny  New York   \n",
      "3      380044344            Pedro's  New York   \n",
      "4      410235438  Trudy's Ice Cream  New York   \n",
      "\n",
      "                                  cuisine   latitude  longitude takeaway  \\\n",
      "0                                 Unknown  40.738597 -74.030349  Unknown   \n",
      "1                                 Unknown  40.743318 -74.028582  Unknown   \n",
      "2                                  korean  40.741558 -73.978463  Unknown   \n",
      "3  mexican;burrito;tacos;nachos;enchilada  40.702532 -73.986565  Unknown   \n",
      "4                                 dessert  40.800377 -73.961806  Unknown   \n",
      "\n",
      "  delivery                                      opening_hours  \n",
      "0  Unknown                                            Unknown  \n",
      "1  Unknown      Mo-Sa 16:30-23:00; Su 11:00-15:00,16:30-22:00  \n",
      "2  Unknown  Mo-Th 12:00-22:00; Fr-Sa 12:00-23:00; Su 12:00...  \n",
      "3  Unknown                                  Mo-Su 12:00-23:00  \n",
      "4  Unknown               Mo-Fr 12:00-21:00; Sa-Su 11:00-21:00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data and examine structure\n",
    "print(\"Loading data and examining structure...\")\n",
    "weather_df = pd.read_csv('../data/weather_data.csv')\n",
    "restaurant_df = pd.read_csv('../data/restaurant_data.csv')\n",
    "\n",
    "print(\"\\nWeather Data Columns:\")\n",
    "print(weather_df.columns.tolist())\n",
    "print(\"\\nFirst few rows of weather data:\")\n",
    "print(weather_df.head())\n",
    "\n",
    "print(\"\\nRestaurant Data Columns:\")\n",
    "print(restaurant_df.columns.tolist())\n",
    "print(\"\\nFirst few rows of restaurant data:\")\n",
    "print(restaurant_df.head())\n",
    "\n",
    "\n",
    "\n",
    "### check data quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Restaurant Data Collection\n",
    "\n",
    "Using publicly available restaurant data and generating synthetic delivery metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting restaurant data from OpenStreetMap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving restaurant data...\n",
      "Restaurant data saved successfully!\n",
      "\n",
      "Restaurant Data Summary:\n",
      "Total restaurants: 9022\n",
      "\n",
      "Restaurants per city:\n",
      "city\n",
      "New York       5475\n",
      "Chicago        1721\n",
      "Los Angeles    1065\n",
      "Houston         455\n",
      "Phoenix         306\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cuisine types:\n",
      "cuisine\n",
      "Unknown    2181\n",
      "mexican     653\n",
      "pizza       566\n",
      "italian     482\n",
      "chinese     471\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define major US cities with their coordinates\n",
    "cities = {\n",
    "    'New York': {'lat': 40.7128, 'lon': -74.0060},\n",
    "    'Los Angeles': {'lat': 34.0522, 'lon': -118.2437},\n",
    "    'Chicago': {'lat': 41.8781, 'lon': -87.6298},\n",
    "    'Houston': {'lat': 29.7604, 'lon': -95.3698},\n",
    "    'Phoenix': {'lat': 33.4484, 'lon': -112.0740}\n",
    "}\n",
    "\n",
    "def get_restaurant_data(cities):\n",
    "    \"\"\"Collect restaurant data using OpenStreetMap Overpass API (no key needed)\"\"\"\n",
    "    import requests\n",
    "    import time\n",
    "    from tqdm import tqdm\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Overpass API endpoint\n",
    "    overpass_url = \"https://overpass-api.de/api/interpreter\"\n",
    "    restaurants = []\n",
    "    \n",
    "    for city, coords in tqdm(cities.items()):\n",
    "        # Create a bounding box around the city coordinates (roughly 10km radius)\n",
    "        lat, lon = coords['lat'], coords['lon']\n",
    "        radius = 0.1  # roughly 10km in degrees\n",
    "        bbox = f\"{lat-radius},{lon-radius},{lat+radius},{lon+radius}\"\n",
    "        \n",
    "        # Overpass query to get restaurants\n",
    "        overpass_query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        (\n",
    "          node[\"amenity\"=\"restaurant\"]({bbox});\n",
    "          way[\"amenity\"=\"restaurant\"]({bbox});\n",
    "          relation[\"amenity\"=\"restaurant\"]({bbox});\n",
    "        );\n",
    "        out body;\n",
    "        >;\n",
    "        out skel qt;\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(overpass_url, data={\"data\": overpass_query})\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            for element in data.get('elements', []):\n",
    "                if element.get('type') == 'node':  # Only process node elements for simplicity\n",
    "                    tags = element.get('tags', {})\n",
    "                    restaurant = {\n",
    "                        'restaurant_id': str(element['id']),\n",
    "                        'name': tags.get('name', 'Unknown'),\n",
    "                        'city': city,\n",
    "                        'cuisine': tags.get('cuisine', 'Unknown'),\n",
    "                        'latitude': element['lat'],\n",
    "                        'longitude': element['lon'],\n",
    "                        'takeaway': tags.get('takeaway', 'Unknown'),\n",
    "                        'delivery': tags.get('delivery', 'Unknown'),\n",
    "                        'opening_hours': tags.get('opening_hours', 'Unknown')\n",
    "                    }\n",
    "                    restaurants.append(restaurant)\n",
    "            \n",
    "            # Be nice to the API\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {city}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(restaurants)\n",
    "\n",
    "# Get restaurant data\n",
    "print(\"Collecting restaurant data from OpenStreetMap...\")\n",
    "restaurant_df = get_restaurant_data(cities)\n",
    "\n",
    "# Clean up the data\n",
    "restaurant_df = restaurant_df[restaurant_df['name'] != 'Unknown']  # Remove unnamed restaurants\n",
    "\n",
    "# Save to CSV\n",
    "print(\"\\nSaving restaurant data...\")\n",
    "restaurant_df.to_csv('../data/restaurant_data.csv', index=False)\n",
    "print(\"Restaurant data saved successfully!\")\n",
    "\n",
    "# Display some statistics\n",
    "print(\"\\nRestaurant Data Summary:\")\n",
    "print(f\"Total restaurants: {len(restaurant_df)}\")\n",
    "print(\"\\nRestaurants per city:\")\n",
    "print(restaurant_df['city'].value_counts())\n",
    "print(\"\\nCuisine types:\")\n",
    "print(restaurant_df['cuisine'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Cleaning data...\n",
      "Creating master dataset...\n",
      "\n",
      "Saving master dataset...\n",
      "\n",
      "Generating basic analysis...\n",
      "\n",
      "Master dataset created successfully!\n",
      "Files generated:\n",
      "1. master_delivery_data.csv - Complete merged dataset\n",
      "2. restaurant_distribution.png - Restaurant distribution visualization\n",
      "3. temperature_distribution.png - Temperature distribution visualization\n",
      "4. cuisine_distribution.png - Cuisine distribution visualization\n",
      "5. master_data_summary.txt - Summary statistics\n",
      "\n",
      "Key Statistics:\n",
      "Total Records: 1063620\n",
      "Unique Restaurants: 9022\n",
      "Cities Covered: 5\n",
      "Average Temperature: 39.7°F\n",
      "Restaurants with Delivery: 124865 (11.7%)\n",
      "Most Common Cuisine: Unknown\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Load data\n",
    "print(\"Loading data...\")\n",
    "weather_df = pd.read_csv('../data/weather_data.csv')\n",
    "restaurant_df = pd.read_csv('../data/restaurant_data.csv')\n",
    "\n",
    "# 2. Clean and prepare data\n",
    "def clean_restaurant_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert delivery/takeaway to binary\n",
    "    df['has_delivery'] = df['delivery'].map({'yes': 1, 'no': 0, 'Unknown': 0})\n",
    "    df['has_takeaway'] = df['takeaway'].map({'yes': 1, 'no': 0, 'Unknown': 0})\n",
    "    \n",
    "    # Clean cuisine\n",
    "    df['cuisine'] = df['cuisine'].fillna('Unknown')\n",
    "    \n",
    "    # Extract opening hours where available\n",
    "    df['has_opening_hours'] = df['opening_hours'].ne('Unknown').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_weather_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert temperature to Fahrenheit if it's in Celsius\n",
    "    if df['temperature'].mean() < 10:  # Likely Celsius\n",
    "        df['temperature_F'] = df['temperature'] * 9/5 + 32\n",
    "    else:\n",
    "        df['temperature_F'] = df['temperature']\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['precipitation'] = df['precipitation'].fillna(0)\n",
    "    df['windSpeed'] = df['windSpeed'].fillna(df['windSpeed'].mean())\n",
    "    df['humidity'] = df['humidity'].fillna(df['humidity'].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Clean the data\n",
    "print(\"\\nCleaning data...\")\n",
    "weather_clean = clean_weather_data(weather_df)\n",
    "restaurant_clean = clean_restaurant_data(restaurant_df)\n",
    "\n",
    "# 3. Create master dataset\n",
    "def create_master_dataset(weather_df, restaurant_df):\n",
    "    \"\"\"Merge weather and restaurant data based on city\"\"\"\n",
    "    \n",
    "    # Create master data\n",
    "    master_data = []\n",
    "    \n",
    "    # Get current timestamp for reference\n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    for city in weather_df['city'].unique():\n",
    "        # Get weather data for this city\n",
    "        city_weather = weather_df[weather_df['city'] == city]\n",
    "        # Get restaurants in this city\n",
    "        city_restaurants = restaurant_df[restaurant_df['city'] == city]\n",
    "        \n",
    "        # For each weather record\n",
    "        for _, weather in city_weather.iterrows():\n",
    "            # For each restaurant in the city\n",
    "            for _, restaurant in city_restaurants.iterrows():\n",
    "                master_data.append({\n",
    "                    # Restaurant info\n",
    "                    'restaurant_id': restaurant['restaurant_id'],\n",
    "                    'restaurant_name': restaurant['name'],\n",
    "                    'city': city,\n",
    "                    'cuisine': restaurant['cuisine'],\n",
    "                    'latitude': restaurant['latitude'],\n",
    "                    'longitude': restaurant['longitude'],\n",
    "                    'has_delivery': restaurant['has_delivery'],\n",
    "                    'has_takeaway': restaurant['has_takeaway'],\n",
    "                    'has_opening_hours': restaurant['has_opening_hours'],\n",
    "                    \n",
    "                    # Weather info\n",
    "                    'temperature_F': weather['temperature_F'],\n",
    "                    'precipitation': weather['precipitation'],\n",
    "                    'humidity': weather['humidity'],\n",
    "                    'wind_speed': weather['windSpeed']\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(master_data)\n",
    "\n",
    "# Create master dataset\n",
    "print(\"Creating master dataset...\")\n",
    "master_df = create_master_dataset(weather_clean, restaurant_clean)\n",
    "\n",
    "# Save master dataset\n",
    "print(\"\\nSaving master dataset...\")\n",
    "master_df.to_csv('../data/master_delivery_data.csv', index=False)\n",
    "\n",
    "# 4. Basic Analysis\n",
    "print(\"\\nGenerating basic analysis...\")\n",
    "\n",
    "# Restaurant distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "master_df['city'].value_counts().plot(kind='bar')\n",
    "plt.title('Number of Restaurants by City')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/restaurant_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Temperature distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='city', y='temperature_F', data=master_df)\n",
    "plt.title('Temperature Distribution by City')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Temperature (°F)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/temperature_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Cuisine distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "master_df['cuisine'].value_counts().head(10).plot(kind='bar')\n",
    "plt.title('Top 10 Cuisine Types')\n",
    "plt.xlabel('Cuisine')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/cuisine_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Generate summary statistics\n",
    "summary_stats = {\n",
    "    'Total Records': len(master_df),\n",
    "    'Unique Restaurants': master_df['restaurant_id'].nunique(),\n",
    "    'Cities Covered': master_df['city'].nunique(),\n",
    "    'Average Temperature': f\"{master_df['temperature_F'].mean():.1f}°F\",\n",
    "    'Restaurants with Delivery': f\"{(master_df['has_delivery'] == 1).sum()} ({(master_df['has_delivery'] == 1).mean()*100:.1f}%)\",\n",
    "    'Most Common Cuisine': master_df['cuisine'].mode()[0]\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "with open('../data/master_data_summary.txt', 'w') as f:\n",
    "    f.write(\"Master Dataset Summary\\n\")\n",
    "    f.write(\"====================\\n\\n\")\n",
    "    for key, value in summary_stats.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "print(\"\\nMaster dataset created successfully!\")\n",
    "print(\"Files generated:\")\n",
    "print(\"1. master_delivery_data.csv - Complete merged dataset\")\n",
    "print(\"2. restaurant_distribution.png - Restaurant distribution visualization\")\n",
    "print(\"3. temperature_distribution.png - Temperature distribution visualization\")\n",
    "print(\"4. cuisine_distribution.png - Cuisine distribution visualization\")\n",
    "print(\"5. master_data_summary.txt - Summary statistics\")\n",
    "\n",
    "# Display key statistics\n",
    "print(\"\\nKey Statistics:\")\n",
    "for key, value in summary_stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading master dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishe\\AppData\\Local\\Temp\\ipykernel_66564\\368655633.py:110: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  pivot_table = pd.pivot_table(\n",
      "C:\\Users\\rishe\\AppData\\Local\\Temp\\ipykernel_66564\\368655633.py:137: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  'highest_delivery_temp': master_df.groupby('temp_category')['has_delivery'].mean().idxmax(),\n",
      "C:\\Users\\rishe\\AppData\\Local\\Temp\\ipykernel_66564\\368655633.py:138: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  'lowest_delivery_temp': master_df.groupby('temp_category')['has_delivery'].mean().idxmin()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather-based delivery analysis complete! Check the 'weather_delivery_analysis' folder for:\n",
      "1. Temperature impact visualization\n",
      "2. Precipitation impact visualization\n",
      "3. Wind speed impact visualization\n",
      "4. Weather conditions matrix\n",
      "5. Cuisine-specific weather impact\n",
      "6. City-specific weather impact\n",
      "7. Combined weather effects\n",
      "8. Weather correlation analysis\n",
      "9. Detailed statistical analysis in 'weather_impact_analysis.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishe\\AppData\\Local\\Temp\\ipykernel_66564\\368655633.py:149: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  'optimal_wind_speed': master_df.groupby('wind_category')['has_delivery'].mean().idxmax()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the master dataset\n",
    "print(\"Loading master dataset...\")\n",
    "master_df = pd.read_csv('../data/master_delivery_data.csv')\n",
    "\n",
    "# Create weather-based delivery analysis directory\n",
    "import os\n",
    "if not os.path.exists('../weather_delivery_analysis'):\n",
    "    os.makedirs('../weather_delivery_analysis')\n",
    "\n",
    "# Set figure style\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# 1. Temperature Impact on Delivery\n",
    "plt.figure()\n",
    "master_df['temp_category'] = pd.cut(\n",
    "    master_df['temperature_F'],\n",
    "    bins=[0, 32, 50, 68, 86, 100],\n",
    "    labels=['Very Cold', 'Cold', 'Moderate', 'Warm', 'Hot']\n",
    ")\n",
    "sns.boxplot(data=master_df, x='temp_category', y='has_delivery')\n",
    "plt.title('Temperature Impact on Delivery Service Usage', pad=20)\n",
    "plt.xlabel('Temperature Category')\n",
    "plt.ylabel('Delivery Service Usage Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../weather_delivery_analysis/1_temp_impact.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Precipitation vs Delivery\n",
    "plt.figure()\n",
    "master_df['rain_category'] = pd.cut(\n",
    "    master_df['precipitation'],\n",
    "    bins=[-np.inf, 0, 0.1, 0.3, np.inf],\n",
    "    labels=['No Rain', 'Light Rain', 'Moderate Rain', 'Heavy Rain']\n",
    ")\n",
    "sns.barplot(data=master_df, x='rain_category', y='has_delivery')\n",
    "plt.title('Precipitation Impact on Delivery Service', pad=20)\n",
    "plt.xlabel('Precipitation Level')\n",
    "plt.ylabel('Delivery Service Usage Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../weather_delivery_analysis/2_rain_impact.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Wind Speed Effect\n",
    "plt.figure()\n",
    "master_df['wind_category'] = pd.cut(\n",
    "    master_df['wind_speed'],\n",
    "    bins=[0, 5, 10, 15, np.inf],\n",
    "    labels=['Light', 'Moderate', 'Strong', 'Very Strong']\n",
    ")\n",
    "sns.barplot(data=master_df, x='wind_category', y='has_delivery')\n",
    "plt.title('Wind Speed Impact on Delivery Service', pad=20)\n",
    "plt.xlabel('Wind Speed Category')\n",
    "plt.ylabel('Delivery Service Usage Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../weather_delivery_analysis/3_wind_impact.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. Weather Conditions Matrix\n",
    "plt.figure(figsize=(15, 10))\n",
    "weather_delivery_matrix = pd.crosstab(\n",
    "    master_df['temp_category'],\n",
    "    master_df['rain_category'],\n",
    "    values=master_df['has_delivery'],\n",
    "    aggfunc='mean'\n",
    ")\n",
    "sns.heatmap(weather_delivery_matrix, annot=True, cmap='YlOrRd', fmt='.2f')\n",
    "plt.title('Delivery Service Usage by Temperature and Precipitation', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../weather_delivery_analysis/4_weather_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 5. Cuisine-specific Weather Impact\n",
    "plt.figure(figsize=(15, 8))\n",
    "top_cuisines = master_df['cuisine'].value_counts().head(5).index\n",
    "cuisine_weather = master_df[master_df['cuisine'].isin(top_cuisines)]\n",
    "sns.boxplot(data=cuisine_weather, x='cuisine', y='has_delivery', hue='temp_category')\n",
    "plt.title('Weather Impact on Delivery by Cuisine Type', pad=20)\n",
    "plt.xlabel('Cuisine Type')\n",
    "plt.ylabel('Delivery Service Usage Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('../weather_delivery_analysis/5_cuisine_weather.png')\n",
    "plt.close()\n",
    "\n",
    "# 6. Weather Impact by City\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(data=master_df, x='city', y='has_delivery', hue='temp_category')\n",
    "plt.title('Weather Impact on Delivery by City', pad=20)\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Delivery Service Usage Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig('../weather_delivery_analysis/6_city_weather.png')\n",
    "plt.close()\n",
    "\n",
    "# 7. Combined Weather Effects\n",
    "plt.figure(figsize=(12, 8))\n",
    "pivot_table = pd.pivot_table(\n",
    "    master_df, \n",
    "    values='has_delivery',\n",
    "    index='temp_category',\n",
    "    columns='rain_category',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "sns.heatmap(pivot_table, annot=True, cmap='coolwarm', center=0.5, fmt='.2f')\n",
    "plt.title('Combined Weather Effects on Delivery Service', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../weather_delivery_analysis/7_combined_weather.png')\n",
    "plt.close()\n",
    "\n",
    "# 8. Weather Correlation Analysis\n",
    "plt.figure(figsize=(10, 8))\n",
    "weather_cols = ['temperature_F', 'precipitation', 'humidity', 'wind_speed', 'has_delivery']\n",
    "correlation = master_df[weather_cols].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Weather Factors Correlation with Delivery', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../weather_delivery_analysis/8_correlation.png')\n",
    "plt.close()\n",
    "\n",
    "# Generate statistical analysis\n",
    "weather_stats = {\n",
    "    'Temperature Effect': {\n",
    "        'correlation': master_df['temperature_F'].corr(master_df['has_delivery']),\n",
    "        'highest_delivery_temp': master_df.groupby('temp_category')['has_delivery'].mean().idxmax(),\n",
    "        'lowest_delivery_temp': master_df.groupby('temp_category')['has_delivery'].mean().idxmin()\n",
    "    },\n",
    "    'Precipitation Effect': {\n",
    "        'correlation': master_df['precipitation'].corr(master_df['has_delivery']),\n",
    "        'rain_vs_no_rain': (\n",
    "            master_df[master_df['precipitation'] > 0]['has_delivery'].mean() /\n",
    "            master_df[master_df['precipitation'] == 0]['has_delivery'].mean()\n",
    "        )\n",
    "    },\n",
    "    'Wind Effect': {\n",
    "        'correlation': master_df['wind_speed'].corr(master_df['has_delivery']),\n",
    "        'optimal_wind_speed': master_df.groupby('wind_category')['has_delivery'].mean().idxmax()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save analysis results\n",
    "with open('../weather_delivery_analysis/weather_impact_analysis.txt', 'w') as f:\n",
    "    f.write(\"Weather Impact on Food Delivery Analysis\\n\")\n",
    "    f.write(\"=====================================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Temperature Effects:\\n\")\n",
    "    f.write(f\"- Correlation with delivery: {weather_stats['Temperature Effect']['correlation']:.3f}\\n\")\n",
    "    f.write(f\"- Highest delivery rate: {weather_stats['Temperature Effect']['highest_delivery_temp']}\\n\")\n",
    "    f.write(f\"- Lowest delivery rate: {weather_stats['Temperature Effect']['lowest_delivery_temp']}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Precipitation Effects:\\n\")\n",
    "    f.write(f\"- Correlation with delivery: {weather_stats['Precipitation Effect']['correlation']:.3f}\\n\")\n",
    "    f.write(f\"- Rain vs No Rain delivery ratio: {weather_stats['Precipitation Effect']['rain_vs_no_rain']:.2f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Wind Effects:\\n\")\n",
    "    f.write(f\"- Correlation with delivery: {weather_stats['Wind Effect']['correlation']:.3f}\\n\")\n",
    "    f.write(f\"- Optimal wind conditions: {weather_stats['Wind Effect']['optimal_wind_speed']}\\n\")\n",
    "\n",
    "print(\"Weather-based delivery analysis complete! Check the 'weather_delivery_analysis' folder for:\")\n",
    "print(\"1. Temperature impact visualization\")\n",
    "print(\"2. Precipitation impact visualization\")\n",
    "print(\"3. Wind speed impact visualization\")\n",
    "print(\"4. Weather conditions matrix\")\n",
    "print(\"5. Cuisine-specific weather impact\")\n",
    "print(\"6. City-specific weather impact\")\n",
    "print(\"7. Combined weather effects\")\n",
    "print(\"8. Weather correlation analysis\")\n",
    "print(\"9. Detailed statistical analysis in 'weather_impact_analysis.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
